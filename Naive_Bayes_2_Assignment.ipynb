{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a037df-a1cf-4de9-966c-a9e1e3af73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ques 1\n",
    "# Ans -- To find the probability that an employee is a smoker given that he/she uses the health insurance plan, you can use Bayes' theorem. \n",
    "\n",
    "Let's define the following events:\n",
    "- A: Employee uses the health insurance plan.\n",
    "- S: Employee is a smoker.\n",
    "\n",
    "You are given the following probabilities:\n",
    "- P(A) = 70% = 0.70 (probability that an employee uses the health insurance plan).\n",
    "- P(S | A) = 40% = 0.40 (probability that an employee is a smoker given that they use the health insurance plan).\n",
    "\n",
    "Now, you want to find P(S | A), the probability that an employee is a smoker given that they use the health insurance plan.\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "\\[P(S | A) = {P(A | S) * P(S)}/{P(A)}]\n",
    "\n",
    "You are not given P(S), the overall probability that an employee is a smoker, but you can calculate it using the law of total probability:\n",
    "\n",
    "\\[P(S) = P(S | A) * P(A) + P(S | ~A) * P(~A)\\]\n",
    "\n",
    "Here, P(~A) represents the probability that an employee does not use the health insurance plan, and P(S | ~A) represents the probability that an employee is a smoker given that they do not use the health insurance plan.\n",
    "\n",
    "You can assume that the employees who do not use the health insurance plan are also smokers with some probability, which we'll call P(S | ~A), and the rest are non-smokers. Let's assume that P(S | ~A) = 10% = 0.10 (i.e., 10% of employees who do not use the health insurance plan are smokers).\n",
    "\n",
    "Now, you can calculate P(S) using the law of total probability:\n",
    "\n",
    "\\[P(S) = P(S | A) * P(A) + P(S | ~A) * P(~A)\\]\n",
    "\\[P(S) = 0.40 * 0.70 + 0.10 * (1 - 0.70)\\]\n",
    "\\[P(S) = 0.28 + 0.10 * 0.30\\]\n",
    "\\[P(S) = 0.28 + 0.03\\]\n",
    "\\[P(S) = 0.31\\]\n",
    "\n",
    "Now that you have P(S), you can use Bayes' theorem to find P(S | A):\n",
    "\n",
    "\\[P(S | A) = {P(A | S) * P(S)}/{P(A)}]\n",
    "\\[P(S | A) = {P(A | S) * 0.31}/{0.70}\\]\n",
    "\n",
    "You already have P(A | S) = 0.40, so you can calculate:\n",
    "\n",
    "\\[P(S | A) = \\frac{0.40 * 0.31}{0.70}\\]\n",
    "\\[P(S | A) = \\frac{0.124}{0.70}\\]\n",
    "\\[P(S | A) â‰ˆ 0.1771\\]\n",
    "\n",
    "So, the probability that an employee is a smoker given that he/she uses the health insurance plan is approximately 0.1771 or 17.71%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f87c6-5bae-480a-90de-c69738641cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ques 2\n",
    "# Ans -- Bernoulli Naive Bayes and Multinomial Naive Bayes are both variants of the Naive Bayes algorithm used in machine learning for classification tasks, but they are designed for different types of data and have distinct characteristics:\n",
    "\n",
    "1. **Data Type**:\n",
    "   - **Bernoulli Naive Bayes**: It is primarily used for binary or boolean data, where features are either present (1) or absent (0). It's commonly applied in text classification, where each term's presence or absence in a document is considered.\n",
    "   - **Multinomial Naive Bayes**: It is used for discrete data, particularly when dealing with text data in the form of word counts or term frequency (integer counts). It's suitable for situations where you have a discrete count of occurrences of each feature.\n",
    "\n",
    "2. **Feature Representation**:\n",
    "   - **Bernoulli Naive Bayes**: It models the presence or absence of features using binary values (0 or 1). It's well-suited for problems like spam email detection, where you are interested in whether certain words are present or not in an email.\n",
    "   - **Multinomial Naive Bayes**: It works with non-negative integer counts, which represent the frequency of each feature in a document. It's widely used in text classification tasks like document categorization or sentiment analysis.\n",
    "\n",
    "3. **Probability Distributions**:\n",
    "   - **Bernoulli Naive Bayes**: It assumes a Bernoulli distribution for each feature, which models the probability of each feature being present or absent in each class.\n",
    "   - **Multinomial Naive Bayes**: It assumes a Multinomial distribution for each feature, which models the probability distribution of the feature counts (frequencies) in each class.\n",
    "\n",
    "4. **Handling Missing Data**:\n",
    "   - **Bernoulli Naive Bayes**: It can handle missing data naturally by treating missing values as a feature being absent.\n",
    "   - **Multinomial Naive Bayes**: It typically assumes that missing values are equivalent to having a feature count of zero, which may or may not be appropriate depending on the context.\n",
    "\n",
    "5. **Use Cases**:\n",
    "   - **Bernoulli Naive Bayes**: Commonly used in text classification tasks, sentiment analysis, and document categorization when you are interested in the presence or absence of specific keywords or features.\n",
    "   - **Multinomial Naive Bayes**: Widely used in text classification, spam detection, and document analysis when you have discrete feature counts, such as word frequencies or term counts.\n",
    "\n",
    "In summary, the choice between Bernoulli Naive Bayes and Multinomial Naive Bayes depends on the nature of your data and the specific problem you are trying to solve. If you are working with binary data or presence/absence features, Bernoulli Naive Bayes is more appropriate. If you are dealing with discrete feature counts, Multinomial Naive Bayes is a better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c06d66-73bf-4198-9e94-cd3961350d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ques 3\n",
    "# Ans -- Bernoulli Naive Bayes is a variant of the Naive Bayes algorithm designed for binary data, where features are either present (1) or absent (0). Handling missing values in Bernoulli Naive Bayes is relatively straightforward because the algorithm naturally accommodates missing values by treating them as the absence of the corresponding features.\n",
    "\n",
    "Here's how Bernoulli Naive Bayes handles missing values:\n",
    "\n",
    "1. **Treating Missing Values as Feature Absence**: In Bernoulli Naive Bayes, if a feature's value is missing for a particular data point, it is treated as if the feature is absent (i.e., assigned a value of 0). This is consistent with the binary nature of the data, where features are either on (1) or off (0).\n",
    "\n",
    "2. **Probability Estimation**: When estimating probabilities for each feature's presence or absence in each class, Bernoulli Naive Bayes considers the missing values as if they were explicitly assigned a value of 0. It calculates the probability of the feature being absent in each class based on the observed data.\n",
    "\n",
    "3. **Smoothing**: To avoid issues with zero probabilities, which can lead to problems during classification, Laplace smoothing (additive smoothing) is often applied. Smoothing adds a small constant to the counts to ensure that no probability estimate becomes exactly zero, even if there are no observed instances of a feature in a particular class.\n",
    "\n",
    "4. **Classification**: When making predictions for new data points that have missing values for some features, Bernoulli Naive Bayes uses the probabilities it has learned from the training data to compute the likelihood of each class given the observed and missing features. It then combines this likelihood with the prior probabilities to make a classification decision.\n",
    "\n",
    "Here's a simple example to illustrate:\n",
    "\n",
    "Suppose you have a dataset with two binary features, X1 and X2, and the task is to classify whether an email is spam or not. If you encounter a new email with missing values for X1 and X2, Bernoulli Naive Bayes would naturally treat X1 and X2 as absent (both 0) and estimate the probability of these features being absent in each class based on the training data.\n",
    "\n",
    "In summary, Bernoulli Naive Bayes handles missing values by treating them as feature absence (0) and incorporates them into its probability estimation and classification process, often with the use of Laplace smoothing to ensure robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f053e-f733-408a-877e-388a8c434591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ques4\n",
    "# Ans -- Yes, Gaussian Naive Bayes can be used for multi-class classification tasks. Gaussian Naive Bayes is a variant of the Naive Bayes algorithm that is particularly suited for continuous or numerical data. While it is often used for binary classification tasks (where there are only two classes), it can be extended to handle multi-class classification problems as well.\n",
    "\n",
    "In the context of multi-class classification using Gaussian Naive Bayes, the algorithm works as follows:\n",
    "\n",
    "1. **Probability Distribution**: Gaussian Naive Bayes assumes that the features in each class are normally distributed (follow a Gaussian distribution). It models the class-conditional probability distributions for each feature as a Gaussian distribution with a mean and variance specific to each class.\n",
    "\n",
    "2. **Training**: During the training phase, the algorithm estimates the mean and variance of each feature for each class in the training dataset. These parameters are used to build the Gaussian probability distribution for each feature in each class.\n",
    "\n",
    "3. **Classification**: When making predictions for a new data point with multiple features, the algorithm calculates the likelihood of the data point belonging to each class based on the Gaussian distribution parameters learned during training. It then combines these likelihoods with the prior probabilities of the classes (usually assumed to be equal if not specified otherwise) to determine the most likely class for the data point.\n",
    "\n",
    "4. **Decision Rule**: The decision rule for multi-class classification typically involves selecting the class with the highest posterior probability given the input features. This can be done using the Maximum A Posteriori (MAP) estimation.\n",
    "\n",
    "In a multi-class setting, Gaussian Naive Bayes assigns a probability distribution for each feature in each class and calculates the likelihood of observing the given feature values in each class. The class with the highest likelihood is then chosen as the predicted class.\n",
    "\n",
    "While Gaussian Naive Bayes can be used for multi-class classification, it's worth noting that it makes certain assumptions, such as the Gaussian distribution of feature values, which may not always hold true in practice. Depending on the nature of your data, other classifiers like Multinomial Naive Bayes or decision trees may be more suitable for multi-class tasks. Nonetheless, Gaussian Naive Bayes is a useful and simple algorithm that can perform reasonably well in a variety of classification scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b351e577-1c07-4d13-8749-2d5474eca597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#load the dataset\n",
    "data=pd.read_csv('spambase.data' ,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34869027-a7e6-417b-8669-2fc83dd528c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  57  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64548f0c-3adc-4a45-af4f-86b9211043b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the feature(X) and the target variable(y)\n",
    "X=data.iloc[:,:-1]\n",
    "y=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ad6f13-fcac-423b-9d4d-c24d6bf068fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4596</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.142</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.555</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4598</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.404</td>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.147</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4600</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.250</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4601 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3     4     5     6     7     8     9   ...   47  \\\n",
       "0     0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "1     0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.0   \n",
       "2     0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.0   \n",
       "3     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.0   \n",
       "4     0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.0   \n",
       "...    ...   ...   ...  ...   ...   ...   ...   ...   ...   ...  ...  ...   \n",
       "4596  0.31  0.00  0.62  0.0  0.00  0.31  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "4597  0.00  0.00  0.00  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "4598  0.30  0.00  0.30  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "4599  0.96  0.00  0.00  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "4600  0.00  0.00  0.65  0.0  0.00  0.00  0.00  0.00  0.00  0.00  ...  0.0   \n",
       "\n",
       "         48     49   50     51     52     53     54   55    56  \n",
       "0     0.000  0.000  0.0  0.778  0.000  0.000  3.756   61   278  \n",
       "1     0.000  0.132  0.0  0.372  0.180  0.048  5.114  101  1028  \n",
       "2     0.010  0.143  0.0  0.276  0.184  0.010  9.821  485  2259  \n",
       "3     0.000  0.137  0.0  0.137  0.000  0.000  3.537   40   191  \n",
       "4     0.000  0.135  0.0  0.135  0.000  0.000  3.537   40   191  \n",
       "...     ...    ...  ...    ...    ...    ...    ...  ...   ...  \n",
       "4596  0.000  0.232  0.0  0.000  0.000  0.000  1.142    3    88  \n",
       "4597  0.000  0.000  0.0  0.353  0.000  0.000  1.555    4    14  \n",
       "4598  0.102  0.718  0.0  0.000  0.000  0.000  1.404    6   118  \n",
       "4599  0.000  0.057  0.0  0.000  0.000  0.000  1.147    5    78  \n",
       "4600  0.000  0.000  0.0  0.125  0.000  0.000  1.250    5    40  \n",
       "\n",
       "[4601 rows x 57 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "085fdc18-f232-45fa-9a77-30af7c3d9ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "4596    0\n",
       "4597    0\n",
       "4598    0\n",
       "4599    0\n",
       "4600    0\n",
       "Name: 57, Length: 4601, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ec49f33-cc0e-403a-923c-5db487a0cb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes:\n",
      "Accuracy: 0.8839380364047911\n",
      "Precision: 0.8869617393737383\n",
      "Recall: 0.8152389047416673\n",
      "F1 Score: 0.8481249015095276\n"
     ]
    }
   ],
   "source": [
    "# Implementation \n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "bernoulli_nb=BernoulliNB()\n",
    "# Evaluate the classifier using 10-fold cross-validation\n",
    "accuracy_scores = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='accuracy')\n",
    "precision_scores = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='precision')\n",
    "recall_scores = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='recall')\n",
    "f1_scores = cross_val_score(bernoulli_nb, X, y, cv=10, scoring='f1')\n",
    "\n",
    "# Report the performance metrics\n",
    "print(f'Bernoulli Naive Bayes:')\n",
    "print(f'Accuracy: {accuracy_scores.mean()}')\n",
    "print(f'Precision: {precision_scores.mean()}')\n",
    "print(f'Recall: {recall_scores.mean()}')\n",
    "print(f'F1 Score: {f1_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "799f5151-fa98-41ec-8386-bfe29c76395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes:\n",
      "Accuracy: 0.7863496180326323\n",
      "Precision: 0.7393175533565436\n",
      "Recall: 0.7214983911116508\n",
      "F1 Score: 0.7282909724016348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "multinomial_nb = MultinomialNB()\n",
    "\n",
    "# Repeat the evaluation steps as above\n",
    "accuracy_scores = cross_val_score(multinomial_nb, X, y, cv=10, scoring='accuracy')\n",
    "precision_scores = cross_val_score(multinomial_nb, X, y, cv=10, scoring='precision')\n",
    "recall_scores = cross_val_score(multinomial_nb, X, y, cv=10, scoring='recall')\n",
    "f1_scores = cross_val_score(multinomial_nb, X, y, cv=10, scoring='f1')\n",
    "\n",
    "# Report the performance metrics\n",
    "print(f'Multinomial Naive Bayes:')\n",
    "print(f'Accuracy: {accuracy_scores.mean()}')\n",
    "print(f'Precision: {precision_scores.mean()}')\n",
    "print(f'Recall: {recall_scores.mean()}')\n",
    "print(f'F1 Score: {f1_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca57ab5-1838-42ab-86f4-fb61070208ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes:\n",
      "Accuracy: 0.8217730830896915\n",
      "Precision: 0.7103733928118492\n",
      "Recall: 0.9569516119239877\n",
      "F1 Score: 0.8130660909542995\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes classifier\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "# Repeat the evaluation steps as above\n",
    "accuracy_scores = cross_val_score(gaussian_nb, X, y, cv=10, scoring='accuracy')\n",
    "precision_scores = cross_val_score(gaussian_nb, X, y, cv=10, scoring='precision')\n",
    "recall_scores = cross_val_score(gaussian_nb, X, y, cv=10, scoring='recall')\n",
    "f1_scores = cross_val_score(gaussian_nb, X, y, cv=10, scoring='f1')\n",
    "\n",
    "# Report the performance metrics\n",
    "print(f'Gaussian Naive Bayes:')\n",
    "print(f'Accuracy: {accuracy_scores.mean()}')\n",
    "print(f'Precision: {precision_scores.mean()}')\n",
    "print(f'Recall: {recall_scores.mean()}')\n",
    "print(f'F1 Score: {f1_scores.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebda3db-2e6c-4370-9619-d2d1fa6c4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "Discussion --\n",
    "Based on the results, analyze which variant of Naive Bayes performed the best and why you think that is the case. Also, discuss any limitations you observed.\n",
    "\n",
    "Conclusion--\n",
    "Summarize your findings and provide suggestions for future work. This could include exploring other classification algorithms, feature engineering, or optimizing hyperparameters for better performance.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
